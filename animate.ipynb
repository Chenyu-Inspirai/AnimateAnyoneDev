{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from animationpipeline import AnimateInferPipeline, use_raw_vid, use_vid_key_points\n",
    "from src.utils.util import get_fps, read_frames, save_videos_from_pil, save_videos_grid\n",
    "from src.dwpose import DWposeDetector\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.openpose_rescaler import draw, rescale_skeleton\n",
    "from tools import openpose_rescaler\n",
    "import importlib\n",
    "from IPython.display import Video\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = DWposeDetector().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animator = AnimateInferPipeline(\n",
    "    base_model_path='./pretrained_weights/stable-diffusion-v1-5',\n",
    "    reference_unet_path=\"/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/pretrained_weights/opensource_stage1/reference_unet-0.pth\",\n",
    "    denoising_unet_path=\"/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/pretrained_weights/opensource_stage1/denoising_unet-0.pth\", \n",
    "    vae_path='./pretrained_weights/sd-vae-ft-mse',\n",
    "    pose_guider_path=\"/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/pretrained_weights/opensource_stage1/pose_guider-0.pth\",\n",
    "    motion_module_path=\"/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/stage2_out/mmV3/motion_module-3585.pth\",\n",
    "    image_encoder_path='./pretrained_weights/sd-image-variations-diffusers/image_encoder',\n",
    "    infer_config_path=\"/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/configs/inference/inference_v2.yaml\",\n",
    "    # lora_path=\"/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/stage2_out/mmV3_lora_full_data_5e-5/lora-2604.pth\",\n",
    "    # motion_module_path='/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/pretrained_weights/v3_sd15_mm.ckpt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/assets/ref_image/ComfyUI_temp_yeppq_00019_.png\"\n",
    "\n",
    "H = 512\n",
    "W = 512\n",
    "\n",
    "ref_image = cv2.resize(np.array(Image.open(image_dir)), (W,H))\n",
    "ref_pose, score, ref_pose_keypoints = detector(ref_image, output_type='key_points')\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "axs[0].imshow(ref_image)\n",
    "axs[1].imshow(ref_pose)\n",
    "axs[0].axis('off')\n",
    "axs[1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_raw = 1\n",
    "\n",
    "raw_video_dir = '/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/assets/video_clips/tiktok_vlip_0.mp4'\n",
    "\n",
    "pose_vid_dir = '/cephfs/SZ-AI/usr/liuchenyu/HaiLook/vid_dataset_hdtf_tiktok/videos_dwpose/00054.mp4'\n",
    "\n",
    "if use_raw:\n",
    "    pil_vid, pose_vid_dir = use_raw_vid(\n",
    "        raw_video_dir,\n",
    "        W,\n",
    "        H,\n",
    "        detector,\n",
    "        'lean_on_arm',\n",
    "        # ref_pose_keypoints,\n",
    "        start_frame=547,\n",
    "        end_frame=582\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    pil_vid = read_frames(pose_vid_dir)\n",
    "    print(\"Loaded dwpose frames, total frames =\", len(pil_vid))\n",
    "    \n",
    "for i in range(len(pil_vid)):\n",
    "        pil_vid[i] = Image.fromarray(cv2.resize(np.array(pil_vid[i]), (W,H), interpolation=cv2.INTER_LINEAR))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vid = animator.animate(\n",
    "    ref_image=ref_image, \n",
    "    pose_list=pil_vid, \n",
    "    width=W, \n",
    "    height=H,\n",
    "    video_length=35,\n",
    "    num_inference_steps=20,\n",
    "    cfg=3.5,\n",
    "    seed=42,\n",
    "    context_frames=16\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_video_name = 'leaning_v3'\n",
    "\n",
    "save_video_dir = '/cephfs/SZ-AI/usr/liuchenyu/HaiLook/Moore-AnimateAnyone/output/inference/' + save_video_name + '.mp4'\n",
    "\n",
    "save_videos_grid(res_vid, save_video_dir,n_rows=1,fps=30)\n",
    "\n",
    "Video(save_video_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animateAnyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
